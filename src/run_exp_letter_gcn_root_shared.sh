

python3.6 train_agent.py --algo ppo --env Letter-7x7-v3 --log-interval 5 --save-interval 20 --frames 10000000 --discount 0.94 --ltl-sampler Eventually_1_5_1_4 --epochs 4 --lr 0.0003 --seed 1 --gnn GCN_8x32_ROOT_SHARED --use-dfa --use-mean-guard-embed;
python3.6 train_agent.py --algo ppo --env Letter-7x7-v3 --log-interval 5 --save-interval 20 --frames 10000000 --discount 0.94 --ltl-sampler Eventually_1_5_1_4 --epochs 4 --lr 0.0003 --seed 2 --gnn GCN_8x32_ROOT_SHARED --use-dfa --use-mean-guard-embed;
python3.6 train_agent.py --algo ppo --env Letter-7x7-v3 --log-interval 5 --save-interval 20 --frames 10000000 --discount 0.94 --ltl-sampler Eventually_1_5_1_4 --epochs 4 --lr 0.0003 --seed 3 --gnn GCN_8x32_ROOT_SHARED --use-dfa --use-mean-guard-embed;
python3.6 train_agent.py --algo ppo --env Letter-7x7-v3 --log-interval 5 --save-interval 20 --frames 10000000 --discount 0.94 --ltl-sampler Eventually_1_5_1_4 --epochs 4 --lr 0.0003 --seed 4 --gnn GCN_8x32_ROOT_SHARED --use-dfa --use-mean-guard-embed;
python3.6 train_agent.py --algo ppo --env Letter-7x7-v3 --log-interval 5 --save-interval 20 --frames 10000000 --discount 0.94 --ltl-sampler Eventually_1_5_1_4 --epochs 4 --lr 0.0003 --seed 5 --gnn GCN_8x32_ROOT_SHARED --use-dfa --use-mean-guard-embed;
python3.6 train_agent.py --algo ppo --env Letter-7x7-v3 --log-interval 5 --save-interval 20 --frames 10000000 --discount 0.94 --ltl-sampler Eventually_1_5_1_4 --epochs 4 --lr 0.0003 --seed 6 --gnn GCN_8x32_ROOT_SHARED --use-dfa --use-mean-guard-embed;
python3.6 train_agent.py --algo ppo --env Letter-7x7-v3 --log-interval 5 --save-interval 20 --frames 10000000 --discount 0.94 --ltl-sampler Eventually_1_5_1_4 --epochs 4 --lr 0.0003 --seed 7 --gnn GCN_8x32_ROOT_SHARED --use-dfa --use-mean-guard-embed;
python3.6 train_agent.py --algo ppo --env Letter-7x7-v3 --log-interval 5 --save-interval 20 --frames 10000000 --discount 0.94 --ltl-sampler Eventually_1_5_1_4 --epochs 4 --lr 0.0003 --seed 8 --gnn GCN_8x32_ROOT_SHARED --use-dfa --use-mean-guard-embed;
python3.6 train_agent.py --algo ppo --env Letter-7x7-v3 --log-interval 5 --save-interval 20 --frames 10000000 --discount 0.94 --ltl-sampler Eventually_1_5_1_4 --epochs 4 --lr 0.0003 --seed 9 --gnn GCN_8x32_ROOT_SHARED --use-dfa --use-mean-guard-embed;
python3.6 train_agent.py --algo ppo --env Letter-7x7-v3 --log-interval 5 --save-interval 20 --frames 10000000 --discount 0.94 --ltl-sampler Eventually_1_5_1_4 --epochs 4 --lr 0.0003 --seed 10 --gnn GCN_8x32_ROOT_SHARED --use-dfa --use-mean-guard-embed;

